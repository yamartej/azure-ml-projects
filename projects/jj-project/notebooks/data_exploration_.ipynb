{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de Límites de Crédito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. - CARGA DE LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. -Carga de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path_training = os.path.abspath('../data/train-data/data_training.csv')\n",
    "#file_path_test = os.path.abspath('../data/test-data/data_training.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training and test dataset\n",
    "df_training = pd.read_csv('../data/train-data/data_training.csv', sep=';', index_col='ID', na_values='#N/D')\n",
    "df_test = pd.read_csv('../data/test-data/data_test.csv', sep=';', index_col='ID', na_values='#N/D')\n",
    "\n",
    "# display the first few rows of the training dataset\n",
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar todas las columnas\n",
    "for column in df_training.columns:\n",
    "  print(f\"Column name: {column}\")\n",
    "  print(f\"Data type: {df_training[column].dtype}\")\n",
    "  print(f\"Number of unique values: {df_training[column].nunique()}\")\n",
    "  print(f\"Number of missing values: {df_training[column].isnull().sum()}\")\n",
    "  print(f\"Sample values: {df_training[column].head(3)}\")\n",
    "  print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones:\n",
    "1.- Se Elimina las columnas que no aportan Informacion para el estudio: Age, Years_employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.drop(columns = ['Age','Years_employed'], inplace = True)\n",
    "df_test.drop(columns = ['Age','Years_employed'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos un análisis de nulos para validar si existen datos faltantes\n",
    "df_training.isna().sum().sort_values(ascending = False)\n",
    "df_test.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Todo bien. No existen datos nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función de variables categóricas\n",
    "def graficos_eda_categoricos(cat):\n",
    "    \n",
    "    #Calculamos el número de filas que necesitamos\n",
    "    from math import ceil\n",
    "    filas = ceil(cat.shape[1] / 2)\n",
    "\n",
    "    #Definimos el gráfico\n",
    "    f, ax = plt.subplots(nrows = filas, ncols = 2, figsize = (16, filas * 6))\n",
    "\n",
    "    #Aplanamos para iterar por el gráfico como si fuera de 1 dimensión en lugar de 2\n",
    "    ax = ax.flat \n",
    "\n",
    "    #Creamos el bucle que va añadiendo gráficos\n",
    "    for cada, variable in enumerate(cat):\n",
    "        cat[variable].value_counts().plot.barh(ax = ax[cada])\n",
    "        ax[cada].set_title(variable, fontsize = 12, fontweight = \"bold\")\n",
    "        ax[cada].tick_params(labelsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecutamos la función de variables categóricas.\n",
    "graficos_eda_categoricos(df_training.select_dtypes('O'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to table\n",
    "table_training = pa.Table.from_pandas(df_training)\n",
    "table_test = pa.Table.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write tables out to parquet\n",
    "pq.write_table(table_training, \"../data/train-data/data-training.parquet\", version=\"1.0\")\n",
    "pq.write_table(table_test, \"../data/test-data/data-test.parquet\", version=\"1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a handle to workspace\n",
    "ml_client = MLClient.from_config(credential=credential)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
